---
title: "M1 Macã§node-llama-cppã‚’ä½¿ã£ã¦Elyza-13bã‚’å‹•ã‹ã—ã¦ã¿ãŸ" # è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«
emoji: "ğŸ¦™" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["macOS", "LLM", "llama", "node.js"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: false # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

# ã¯ã˜ã‚ã«

ã€ŒELYZA-japanese-Llama-2-13bã€ã‚·ãƒªãƒ¼ã‚ºã‚’ã€llama.cppã®Node.jsãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã€Œnode-llama-cppã€ã‚’ä½¿ã£ã¦M1 Mac (MacBook Air M1 16GB)ã§å‹•ã‹ã—ã¦ã¿ã¾ã—ãŸã€‚

- [node-llama-cpp](https://github.com/withcatai/node-llama-cpp)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)

# æº–å‚™

- llama.cppã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
  - å‚è€ƒï¼š [M1 Macã§llama.cppã‚’ä½¿ã£ã¦Elyza-13bã‚’å‹•ã‹ã—ã¦ã¿ãŸ - llama.cppã®ãƒ“ãƒ«ãƒ‰](https://zenn.dev/mganeko/articles/llamacpp-elyza-mac#llama.cppã®ãƒ“ãƒ«ãƒ‰)
- ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ãƒ³ãƒ­ãƒ¼ãƒ‰
  - [4bité‡å­åŒ–ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf/resolve/65774113f0e6849051d3669643060e0a650c7d61/ELYZA-japanese-Llama-2-13b-fast-instruct-q4_0.gguf)ã‚’åˆ©ç”¨

# node-llama-cppã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

é©åˆ‡ãªãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œã‚Šã€ãã®ä¸­ã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```
npm install node-llama-cpp
```

## ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™

```
mkdir models
```

modelsãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­ã«ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆLYZA-japanese-Llama-2-13b-fast-instruct-q4_0.ggufï¼‰ã‚’é…ç½®ã™ã‚‹ï¼ˆã‚³ãƒ”ãƒ¼ or ç§»å‹• or ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ï¼‰

## ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

[Getting Started](https://withcatai.github.io/node-llama-cpp/guide/#getting-started)ã‚’å‚è€ƒã«ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ

```mjs
// example.mjs
mport {fileURLToPath} from "url";
import path from "path";
import {LlamaModel, LlamaContext, LlamaChatSession} from "node-llama-cpp";

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const model = new LlamaModel({
    modelPath: path.join(__dirname, "models", "ELYZA-japanese-Llama-2-13b-fast-instruct-q4_0.gguf")

});
const context = new LlamaContext({model});
const session = new LlamaChatSession({context});


// ----- ãƒãƒ£ãƒƒãƒˆ ----
const q1 = "å¯Œå£«å±±ã®é«˜ã•ã¯ï¼Ÿ";
console.log("User: " + q1);
const a1 = await session.prompt(q1);
console.log("AI: " + a1);

const q2 = "ã‚¨ãƒ™ãƒ¬ã‚¹ãƒˆã¯ï¼Ÿ";
console.log("User: " + q2);
const a2 = await session.prompt(q2);
console.log("AI: " + a2);

```

## å®Ÿè¡Œ

```
node exmample.mjs
```

å®Ÿè¡Œçµæœã®ä¾‹
```
User: å¯Œå£«å±±ã®é«˜ã•ã¯ï¼Ÿ
AI: å¯Œå£«å±±ã®é«˜ã•ã¯3776.12 mã§ã™ã€‚
User: ã‚¨ãƒ™ãƒ¬ã‚¹ãƒˆã¯ï¼Ÿ
AI: ã‚¨ãƒ™ãƒ¬ã‚¹ãƒˆã¯8848 mã§ã™ã€‚
```
