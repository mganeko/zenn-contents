---
title: "ã‚¹ãƒãƒ›ã®ã‚«ãƒ¡ãƒ©ã«æ˜ ã‚‹æ™¯è‰²ã‚’éŸ³å£°ã§æ¡ˆå†…ã™ã‚‹ Visual Sonar ã®è©¦ä½œ" # è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«
emoji: "ğŸ“·" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["GPT4-V"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: false # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

# Visual Sonar ã¨ã¯

Visual Sonarã¨ã¯ã€ã‚¹ãƒãƒ›ã®ã‚«ãƒ¡ãƒ©ã«æ˜ ã‚‹æ˜ åƒã‚’è§£æã—ã€éŸ³å£°ã§æ•™ãˆã¦ãã‚Œã‚‹Webã‚¢ãƒ—ãƒªã§ã™ã€‚
OpenAIã®GTP-4ã§ç”»åƒã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ã€ãã‚Œã‚’ä½¿ã£ã¦ä½œã£ã¦ã¿ã¾ã—ãŸã€‚

# æ§‹æˆè¦ç´ 

- mediaDevices.getUserMedia()ã‚’ä½¿ã£ã¦ã€ã‚«ãƒ¡ãƒ©ã®æ˜ åƒå–å¾—
- Cnavasã‚’ä½¿ã£ã¦ã€æ˜ åƒã‹ã‚‰1ã‚³ãƒç”»åƒã‚’å–å¾—
- OpenAIã®gpt-4-vision-previewã‚’ä½¿ã„ã€ç”»åƒã®å†…å®¹ã‚’è§£æ
- OpenAIã®TTS(text-to-speech)ã‚’ä½¿ã„ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«
- Audioè¦ç´ ã§å†ç”Ÿ

# å„éƒ¨ã®å®Ÿè£…ï¼ˆæŠœç²‹ï¼‰

èª¬æ˜ã®ãŸã‚ã«ä¸€éƒ¨æŠœç²‹ã—ã¦ç°¡ç•¥åŒ–ã—ã¦ã„ã¾ã™ã€‚

## ã‚«ãƒ¡ãƒ©æ˜ åƒã®å–å¾—

èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€videoã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€æ¬¡ã®ã‚ˆã†ã«æŒ‡å®šã—ã¾ã™
- video: { facingMode: "environment" }

```js
async function startCamera() {
  const constraints = {
    video: {
      //facingMode: "user" // ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨
      facingMode: "environment" // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨
    }
  };

  // ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã‚’å–å¾—
  const stream = await navigator.mediaDevices.getUserMedia(constraints);

  // <video> è¦ç´ ã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¨­å®š
  localVideo.srcObject = stream;
  await localVideo.play();
}
```

## æ˜ åƒã‹ã‚‰ç”»åƒã‚’Base64ã§å–å¾—

Canvasè¦ç´ ã‚’ä½¿ã„ã€Videoè¦ç´ ã‹ã‚‰1ã‚³ãƒç”»åƒã‚’Base64ã§å–å¾—ã—ã¾ã™ã€‚

```js
  // video ... æ˜ åƒãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹Videoè¦ç´ 
  // canvas ... ä½œæ¥­ã«ä½¿ã†Canvasè¦ç´ 
  // ctx ... canvasã®æç”»ã«ä½¿ã†context
  function getBase64Image(video, canvas, ctx) {
    // Draw Image
    ctx.drawImage(video, 0, 0);

    // To Base64
    return canvas.toDataURL("image/jpeg");
  }
```

## GPT4-V ã§è§£æ

gpt-4-vision-preview ã‚’ä½¿ã£ã¦ã€ç”»åƒã‚’è§£æã—ã¾ã™ã€‚å¾“æ¥ã®Chat APIã¨åŒæ§˜ã§ã™ãŒã€conentãŒå˜ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ãªãã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒURLã®ã‚»ãƒƒãƒˆã«ãªã£ã¦ã„ã‚‹ã®ãŒé•ã„ã§ã™ã€‚

```js
// ç”»åƒã®URL(ã¾ãŸã¯Base64è¡¨è¨˜)ã¨ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã€å¿œç­”ã‚’è¿”ã™
async function singleChatWithImage(image_url, text) {
  // å¾“æ¥ã®Chat APIã¨åŒæ§˜ã ãŒã€conentãŒå˜ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ãªãã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒURLã®ã‚»ãƒƒãƒˆã«ãªã‚‹
  const userMessage = {
    role: 'user',
    content: [
      {
        "type": "text",
        "text": text,
      },
      {
        "type": "image_url",
        "image_url": {
          "url": image_url,
        }
      }
    ]
  };


  // -- request --
  const API_KEY = 'sk-xxxxxxx';
  const MODEL = 'gpt-4-vision-preview';
  const API_URL = 'https://api.openai.com/v1/chat/completions';
  const options = { temperature: 0, max_tokens: 1000 };
  const response = await _chatCompletion([messages], API_KEY, MODEL, API_URL, options);
  return response;
}

// chat API ã‚’å‘¼ã³å‡ºã™
async function _chatCompletion(messages, apiKey, chatModel, url, options) {
  //const apiKey = API_KEY;
  //const CHATAPI_URL = "https://api.openai.com/v1/chat/completions";

  const bodyJson = {
    messages: messages,
    model: chatModel,
    temperature: options.temperature,
    max_tokens: options.max_tokens,
  };
  const body = JSON.stringify(bodyJson);
  const headers = {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    };

  const res = await fetch(url, {
    method: "POST",
    headers: headers,
    body,
  });

  // å¿œç­”ã‚’è§£æ
  const data = await res.json();
  const choiceIndex = 0;
  const choices = data.choices;
  return choices[choiceIndex].message;
};
```
