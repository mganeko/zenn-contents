---
title: "M1 Macã§llama.cppã‚’ä½¿ã£ã¦Elyza-13bã‚’å‹•ã‹ã—ã¦ã¿ãŸ" # è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«
emoji: "ğŸ¦™" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["macOS", "LLM", "llama"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: true # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

# ã¯ã˜ã‚ã«

ã€ŒELYZA-japanese-Llama-2-13bã€ã‚·ãƒªãƒ¼ã‚ºã‚’ã€llama.cppã‚’ä½¿ã£ã¦M1 Mac (MacBook Air M1 16GB)ã§å‹•ã‹ã—ã¦ã¿ã¾ã—ãŸã€‚
llama.cppã¯ã€Metaç¤¾ã®LLaMA/LLaMa 2ã‚’å‹•ã‹ã™ãŸã‚ã®C/C++å®Ÿè£…ã§ã™ã€‚

- [llama.cpp](https://github.com/ggerganov/llama.cpp)

# ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ï¼†é‡å­åŒ–

llama.cppã§ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™ã«ã¯ã€ggufå½¢å¼ã¸ã®å¤‰æ›ãŒå¿…è¦ã§ã™ã€‚ã¾ãŸ13bã®ãƒ¢ãƒ‡ãƒ«ã¯å¤§ãã™ãã‚‹ã®ã§ã€é‡å­åŒ–ã—ã¦ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
momongaã•ã‚“ãŒå¤‰æ›ï¼†é‡å­åŒ–æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¦ã„ã‚‹ã®ã§ã€ãã¡ã‚‰ã‚’ä½¿ã‚ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚

- [mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf](https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf/tree/bd8556cccb46dda6250c112c680aa8c76e6e3000)

# æº–å‚™

## llama.cppã®ãƒ“ãƒ«ãƒ‰

```
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
make -j
```

## ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

8bit, 6bit, 5bit, 4bité‡å­åŒ–ã®ãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ãŒã€8/6bitã§ã¯ç§ã®ç’°å¢ƒã«ã¯å¤§ãã™ãã‚‹ã‚ˆã†ã§ã™ã€‚5bitã§ã‚®ãƒªã‚®ãƒªå‹•ã„ãŸã®ã§ã€ãã¡ã‚‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```
wget https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf/resolve/bd8556cccb46dda6250c112c680aa8c76e6e3000/ELYZA-japanese-Llama-2-13b-fast-instruct-q5_0.gguf
```

# å®Ÿè¡Œ

```
./main -m 'ELYZA-japanese-Llama-2-13b-fast-instruct-q5_0.gguf' -n 32 -p 'å¯Œå£«å±±ã®é«˜ã•ã¯ï¼Ÿ'
```

å‡ºåŠ›ã®ä¾‹
```
 å¯Œå£«å±±ã®é«˜ã•ã¯ï¼Ÿ
A.3776.12 m (2020å¹´8æœˆç¾åœ¨ã®å€¤) [end of text]

llama_print_timings:        load time =     767.14 ms
llama_print_timings:      sample time =      22.81 ms /    23 runs   (    0.99 ms per token,  1008.37 tokens per second)
llama_print_timings: prompt eval time =     551.76 ms /     7 tokens (   78.82 ms per token,    12.69 tokens per second)
llama_print_timings:        eval time =    3490.02 ms /    22 runs   (  158.64 ms per token,     6.30 tokens per second)
llama_print_timings:       total time =    4080.75 ms
```

å®Ÿè¡Œã¯4ç§’ç¨‹åº¦ã§ã™ã€‚ç”Ÿæˆã•ã‚Œã‚‹å†…å®¹ã¯ãƒãƒãƒãƒã§ã€ãŠã‹ã—ãªçµæœã«ãªã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚

# ã¾ã¨ã‚

llama.cppã‚’ä½¿ã†ã“ã¨ã§ã€M1 Macä¸Šã§Elyzaã®13Bã®ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™ã“ã¨ãŒã§ãã¾ã—ãŸã€‚é‡å­åŒ–ã—ã¦ã„ã‚‹ã®ã§åŒæ¡ä»¶ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€AirLLMã‚’ä½¿ã£ãŸå ´åˆã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é«˜é€Ÿã§ã™ã€‚ãã®åˆ†ã€å‡ºåŠ›çµæœã¯ä¸å®‰å®šã«ãªã‚Šã¾ã—ãŸã€‚

- [M1 Macã§AirLLMã‚’ä½¿ã£ã¦Elyza-13bã‚’å‹•ã‹ã—ã¦ã¿ãŸ](https://zenn.dev/mganeko/articles/airllm-elyza-mac)

ã€ŒPowerInferã€ã¨ã„ã†æ‰‹æ³•ã‚‚ç™»å ´ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ã€ç²¾åº¦ã¨å®Ÿè¡Œæ™‚é–“ã®ä¸¡ç«‹ãŒã§ãã‚‹ã®ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚

